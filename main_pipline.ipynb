{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b1e2f6f",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be74468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Hydra는 주피터 노트북에서 특별한 초기화 방식이 필요합니다.\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "\n",
    "\n",
    "from modellib import build, loader, objective\n",
    "from modellib.utils import plots, details, history, gcam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec31c9",
   "metadata": {},
   "source": [
    "## setting cofig load and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e766e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 설정 파일 로드\n",
    "initialize(config_path=\"conf\", version_base=None) \n",
    "cfg = compose(config_name=\"config\")\n",
    "\n",
    "# --- 기본 설정 적용 ---\n",
    "# 재현성을 위한 시드 고정\n",
    "torch.manual_seed(cfg.seed)\n",
    "np.random.seed(cfg.seed)\n",
    "random.seed(cfg.seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(cfg.seed)\n",
    "\n",
    "# GPU 설정\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- 결과 저장 경로 설정 ---\n",
    "# 실험 이름으로 최상위 결과 폴더 생성\n",
    "output_dir = Path(f\"results/{cfg.experiment_name}\")\n",
    "hpo_dir = output_dir / cfg.results_subdirs.hpo\n",
    "models_dir = output_dir / cfg.results_subdirs.models\n",
    "metrics_dir = output_dir / cfg.results_subdirs.metrics\n",
    "gradcam_dir = output_dir / cfg.results_subdirs.gradcam\n",
    "\n",
    "# 폴더 생성\n",
    "hpo_dir.mkdir(parents=True, exist_ok=True)\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "metrics_dir.mkdir(parents=True, exist_ok=True)\n",
    "gradcam_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"🎉 설정 로드 완료! 실험 '{cfg.experiment_name}'을(를) 시작합니다.\")\n",
    "print(f\"DEVICE: {DEVICE}\")\n",
    "print(f\"결과는 '{output_dir}' 폴더에 저장됩니다.\") in: {RUNS_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b9f94",
   "metadata": {},
   "source": [
    "# optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6033f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "opt_hp_path = hpo_dir / \"opt_hp.yaml\"\n",
    "\n",
    "if cfg.hpo.enabled:\n",
    "    print(\"\\n--- 🚀 1단계: 하이퍼파라미터 최적화(HPO) 시작 ---\")\n",
    "    \n",
    "    # Objective 함수 인스턴스 생성\n",
    "    objective_func = objective.Objective(\n",
    "        config=cfg, # config 전체를 넘겨 search_space를 사용하도록 함\n",
    "        data_dir=cfg.data_dir,\n",
    "        backbone=cfg.backbone,\n",
    "        max_epochs=cfg.hpo.max_epochs_per_trial,\n",
    "        n_splits=cfg.split_config.n_splits_cv,\n",
    "        metric_to_optimize=cfg.hpo.metric_to_optimize,\n",
    "        test_ratio=cfg.split_config.test_ratio\n",
    "    )\n",
    "\n",
    "    # Optuna Study 생성\n",
    "    study = optuna.create_study(\n",
    "        study_name=cfg.experiment_name,\n",
    "        direction=objective_func.direction,\n",
    "        sampler=optuna.samplers.TPESampler(seed=cfg.seed),\n",
    "        pruner=optuna.pruners.HyperbandPruner()\n",
    "    )\n",
    "\n",
    "    # HPO 실행\n",
    "    study.optimize(objective_func, n_trials=cfg.hpo.n_trials)\n",
    "\n",
    "    # 최적 하이퍼파라미터 저장\n",
    "    best_params = study.best_trial.params\n",
    "    with open(opt_hp_path, 'w') as f:\n",
    "        yaml.dump(best_params, f, default_flow_style=False)\n",
    "        \n",
    "    print(f\"\\n✅ HPO 완료! 최적 하이퍼파라미터를 '{opt_hp_path}'에 저장했습니다.\")\n",
    "    print(\"최적 하이퍼파라미터:\", best_params)\n",
    "\n",
    "    best_trial = study.best_trial\n",
    "    if 'target_steps_median' not in best_trial.user_attrs:\n",
    "        raise RuntimeError(\"best_trial.user_attrs에 'target_steps_median'이 없습니다. Objective 코드 수정이 누락된 것 같습니다.\")\n",
    "\n",
    "    target_steps_median = int(best_trial.user_attrs['target_steps_median'])\n",
    "    print(f\"📌 median target steps from CV(best trial): {target_steps_median}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n--- ⏩ 1단계: HPO 비활성화. 기존 최적 하이퍼파라미터 파일을 로드합니다. ---\")\n",
    "    if not opt_hp_path.exists():\n",
    "        raise FileNotFoundError(f\"HPO가 비활성화되었지만 '{opt_hp_path}' 파일을 찾을 수 없습니다.\")\n",
    "    print(f\"'{opt_hp_path}' 파일을 사용합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91852c08",
   "metadata": {},
   "source": [
    "# final model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3afd204",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 🚀 2단계: 최종 모델 학습 시작 ---\")\n",
    "# 1. 최적 하이퍼파라미터 로드\n",
    "with open(opt_hp_path, 'r') as f:\n",
    "    best_hp = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 최종 학습용 데이터 로더 준비\n",
    "# CV 때 사용한 Train/Val 데이터를 모두 합쳐서 최종 학습에 사용\n",
    "# val_ratio=0으로 설정하면, test_ratio만큼 분리된 나머지를 모두 학습용으로 사용\n",
    "train_final_loader, _, test_loader, class_names = loader.create_dataloaders(\n",
    "    data_dir=cfg.data_dir,\n",
    "    backbone=cfg.backbone,\n",
    "    batch_size=best_hp['batch_size'],\n",
    "    val_ratio=0, # Val set 없이 전체를 학습에 사용\n",
    "    test_ratio=cfg.split_config.test_ratio,\n",
    "    test_dir=cfg.test_dir\n",
    ")\n",
    "print(f\"최종 학습 데이터셋: {len(train_final_loader.dataset)}개, 테스트 데이터셋: {len(test_loader.dataset)}개\")\n",
    "\n",
    "# steps_per_epoch_full = 배치 업데이트 수\n",
    "steps_per_epoch_full = len(train_final_loader)\n",
    "if steps_per_epoch_full <= 0:\n",
    "    raise RuntimeError(\"steps_per_epoch_full이 0 이하입니다. full-train dataloader 구성이 잘못되었습니다.\")\n",
    "\n",
    "epochs_final = int(math.ceil(target_steps_median / steps_per_epoch_full))\n",
    "print(f\"🎯 epochs_final = ceil({target_steps_median} / {steps_per_epoch_full}) = {epochs_final}\")\n",
    "\n",
    "epochs_final_path = hpo_dir / \"epochs_final.yaml\"\n",
    "with open(epochs_final_path, \"w\") as f:\n",
    "    yaml.dump({\"epochs_final\": epochs_final,\n",
    "               \"target_steps_median\": int(target_steps_median),\n",
    "               \"steps_per_epoch_full\": int(steps_per_epoch_full),\n",
    "               \"fold_best_steps\": best_trial.user_attrs.get(\"fold_best_steps\", []),\n",
    "               \"fold_best_epochs\": best_trial.user_attrs.get(\"fold_best_epochs\", [])}, f)\n",
    "print(f\"📝 최종 학습용 epoch 정보를 '{epochs_final_path}'에 저장했습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfa42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) epochs_final 로드\n",
    "with open(hpo_dir / \"epochs_final.yaml\") as f:\n",
    "    ef = yaml.safe_load(f)\n",
    "epochs_final = int(ef[\"epochs_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ca99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델, 옵티마이저, 스케줄러 준비\n",
    "model = build(\n",
    "    backbone=cfg.backbone,\n",
    "    num_classes=len(class_names),\n",
    "    dropout_rate=best_hp['dropout_rate']\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = getattr(optim, best_hp['optimizer'])(\n",
    "    model.parameters(), lr=best_hp['lr'], weight_decay=best_hp.get('weight_decay', 0.0)\n",
    ")\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-6)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs_final):\n",
    "    # 최종 학습에서는 Train loss만 계산 (Val set이 없으므로)\n",
    "    # 실제로는 validate_one_epoch을 test_loader로 돌려서 성능을 모니터링 할 수 있음\n",
    "    train_loss = objective.train_one_epoch(model, train_final_loader, criterion, optimizer, DEVICE)\n",
    "    val_loss, macro_f1 = objective.validate_one_epoch(model, test_loader, criterion, DEVICE) # 테스트셋으로 검증\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs_final} | Train Loss: {train_loss:.4f} | Test Loss: {val_loss:.4f} | Test Macro-F1: {macro_f1:.4f}\")\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['macro_f1'].append(macro_f1)\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "print(f\"\\n✅ 최종 학습 완료! 가장 성능이 좋은 모델을 '{models_dir}'에 저장했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8912ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 📋 Saving Model Details ---\")\n",
    "\n",
    "# 모델 상세 정보(파라미터 수, 연산량 등) 저장\n",
    "details.save_model_details(\n",
    "    model=model,\n",
    "    save_dir=metrics_dir,\n",
    "    model_name=cfg.experiment_name,\n",
    "    input_size=(1, 3, 224, 224) # 모델에 맞는 사이즈로 조절\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a9851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  히스토리 그래프 저장 및 확인\n",
    "history_plot_path = metrics_dir / f\"{cfg.experiment_name}_history.png\"\n",
    "history.save_history_plot(\n",
    "    history=history,\n",
    "    save_dir=metrics_dir,\n",
    "    model_name=cfg.experiment_name\n",
    ")\n",
    "display.Image(filename=history_plot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb7e411",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473449bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 📊 Evaluating Final Model on Test Set ---\")\n",
    "\n",
    "# 평가 결과물(리포트, 행렬, 곡선) 저장\n",
    "plots.save_classification_results(\n",
    "    model=model,\n",
    "    dataloader=test_loader,\n",
    "    class_names=class_names,\n",
    "    save_dir=metrics_dir,\n",
    "    model_name=cfg.experiment_name,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d4d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 👁️‍🗨️ Generating Grad-CAM Visualizations ---\")\n",
    "\n",
    "gcam.visualize_and_save_gcam_results(\n",
    "    model=model,\n",
    "    dataloader=test_loader,\n",
    "    class_names=class_names,\n",
    "    save_dir=gradcam_dir,\n",
    "    device=DEVICE,\n",
    "    n_true_preds=5,\n",
    "    n_misclassified=5\n",
    ")\n",
    "\n",
    "print(\"\\n🎉 Grad-CAM 분석이 완료되었습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d510da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n🎉🎉🎉 All processes are complete! 🎉🎉🎉\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
